{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from ultralytics import YOLO\n",
    "from sort import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class TrafficViolationSystem:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.histograms = self.load_histograms()\n",
    "        self.model = YOLO('yolov8n.pt')\n",
    "        self.tracker = Sort(max_age=15, min_hits=3)\n",
    "        self.violations = []\n",
    "        self.red_light_intervals = []\n",
    "        self.current_red_interval = None\n",
    "        self.frame_buffer = []\n",
    "        self.plate_cache = {}\n",
    "        self.tracking_summary = defaultdict(dict)\n",
    "\n",
    "    def load_histograms(self):\n",
    "        histograms = {}\n",
    "        for label, path in self.config['histogram_files'].items():\n",
    "            with open(path, 'rb') as f:\n",
    "                histograms[label] = pickle.load(f)\n",
    "        return histograms\n",
    "\n",
    "    def calculate_histogram(self, frame):\n",
    "        height, width = frame.shape[:2]\n",
    "        x_center, y_center, w, h = self.config['traffic_light_bbox']\n",
    "        x_min = int((x_center - w/2) * width)\n",
    "        x_max = int((x_center + w/2) * width)\n",
    "        y_min = int((y_center - h/2) * height)\n",
    "        y_max = int((y_center + h/2) * height)\n",
    "        \n",
    "        roi = frame[y_min:y_max, x_min:x_max]\n",
    "        hist = cv2.calcHist([roi], [0,1,2], None, [8,8,8], [0,256]*3)\n",
    "        return cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "    def detect_traffic_light(self, frame):\n",
    "        frame_hist = self.calculate_histogram(frame)\n",
    "        best_match, best_score = None, -1\n",
    "        for label, hist in self.histograms.items():\n",
    "            score = cv2.compareHist(frame_hist, hist, cv2.HISTCMP_CORREL)\n",
    "            if score > best_score:\n",
    "                best_score, best_match = score, label\n",
    "        return best_match, best_score\n",
    "\n",
    "    def detect_vehicles(self, frame):\n",
    "        results = self.model(frame)\n",
    "        detections = []\n",
    "        for box in results[0].boxes.data:\n",
    "            x1, y1, x2, y2, conf, cls = map(float, box)\n",
    "            if int(cls) == 2:  # Car class\n",
    "                detections.append([x1, y1, x2, y2, conf])\n",
    "        return np.array(detections) if detections else np.empty((0, 5))\n",
    "\n",
    "    def is_within_violation_zone(self, x, y):\n",
    "        x_center, y_center, w, h = self.config['violation_zone_bbox']\n",
    "        x_min = int((x_center - w/2) * self.video_width)\n",
    "        x_max = int((x_center + w/2) * self.video_width)\n",
    "        y_min = int((y_center - h/2) * self.video_height)\n",
    "        y_max = int((y_center + h/2) * self.video_height)\n",
    "        return x_min <= x <= x_max and y_min <= y <= y_max\n",
    "\n",
    "    def track_violations(self, frame, frame_number):\n",
    "        detections = self.detect_vehicles(frame)\n",
    "        tracked_objs = self.tracker.update(detections)\n",
    "        \n",
    "        for obj in tracked_objs:\n",
    "            x1, y1, x2, y2, track_id = map(int, obj)\n",
    "            cx, cy = (x1+x2)//2, (y1+y2)//2\n",
    "            \n",
    "            if not self.is_within_violation_zone(cx, cy):\n",
    "                continue\n",
    "            \n",
    "            if track_id not in self.tracking_summary:\n",
    "                self.tracking_summary[track_id] = {\n",
    "                    'first_seen': frame_number,\n",
    "                    'last_seen': frame_number,\n",
    "                    'violation_frames': [],\n",
    "                    'plate_number': 'UNKNOWN'\n",
    "                }\n",
    "            \n",
    "            self.tracking_summary[track_id]['last_seen'] = frame_number\n",
    "            self.tracking_summary[track_id]['violation_frames'].append(frame_number)\n",
    "            \n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0,0,255), 2)\n",
    "            cv2.putText(frame, f\"ID: {track_id}\", (x1, y1-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
    "\n",
    "    def process_video(self):\n",
    "        cap = cv2.VideoCapture(self.config['input_video'])\n",
    "        self.video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        writer = cv2.VideoWriter(self.config['output_video'], \n",
    "                               cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "                               fps, (self.video_width, self.video_height))\n",
    "        \n",
    "        red_active = False\n",
    "        for frame_num in tqdm(range(total_frames), desc=\"Processing Frames\"):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            \n",
    "            light_status, _ = self.detect_traffic_light(frame)\n",
    "            \n",
    "            # Red light state management\n",
    "            if light_status == 'Red' and not red_active:\n",
    "                red_active = True\n",
    "                self.current_red_interval = {\n",
    "                    'start_frame': frame_num,\n",
    "                    'start_time': frame_num/fps,\n",
    "                    'end_frame': None,\n",
    "                    'end_time': None\n",
    "                }\n",
    "                self.frame_buffer = []\n",
    "            elif light_status != 'Red' and red_active:\n",
    "                red_active = False\n",
    "                self.current_red_interval['end_frame'] = frame_num\n",
    "                self.current_red_interval['end_time'] = frame_num/fps\n",
    "                self.red_light_intervals.append(self.current_red_interval)\n",
    "                self.save_redlight_clip()\n",
    "                self.frame_buffer = []\n",
    "            \n",
    "            if red_active:\n",
    "                self.track_violations(frame, frame_num)\n",
    "                self.frame_buffer.append(frame.copy())\n",
    "            \n",
    "            writer.write(frame)\n",
    "        \n",
    "        cap.release()\n",
    "        writer.release()\n",
    "        self.process_license_plates()\n",
    "        self.generate_output()\n",
    "\n",
    "    def save_redlight_clip(self):\n",
    "        if not self.frame_buffer:\n",
    "            return\n",
    "        \n",
    "        clip_path = os.path.join(\n",
    "            self.config['output_folder'],\n",
    "            f\"redlight_{len(self.red_light_intervals)}.mp4\"\n",
    "        )\n",
    "        \n",
    "        h, w = self.frame_buffer[0].shape[:2]\n",
    "        writer = cv2.VideoWriter(clip_path, cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "                               self.config['output_fps'], (w, h))\n",
    "        for f in self.frame_buffer:\n",
    "            writer.write(f)\n",
    "        writer.release()\n",
    "\n",
    "    def process_license_plates(self):\n",
    "        api_key = self.config['plate_api_key']\n",
    "        for track_id, data in tqdm(self.tracking_summary.items(), desc=\"Processing Plates\"):\n",
    "            try:\n",
    "                frame_num = data['violation_frames'][0]\n",
    "                cap = cv2.VideoCapture(self.config['input_video'])\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "                ret, frame = cap.read()\n",
    "                \n",
    "                if ret:\n",
    "                    x1, y1, x2, y2 = data['bbox']  # Store bbox from tracking\n",
    "                    cropped = frame[y1:y2, x1:x2]\n",
    "                    cv2.imwrite('temp.jpg', cropped)\n",
    "                    \n",
    "                    plate = self.recognize_plate('temp.jpg', api_key)\n",
    "                    data['plate_number'] = plate\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing track {track_id}: {str(e)}\")\n",
    "            finally:\n",
    "                cap.release()\n",
    "\n",
    "    def recognize_plate(self, image_path, api_key, retries=3):\n",
    "        for _ in range(retries):\n",
    "            try:\n",
    "                with open(image_path, 'rb') as f:\n",
    "                    response = requests.post(\n",
    "                        'https://api.platerecognizer.com/v1/plate-reader/',\n",
    "                        files={'upload': f},\n",
    "                        headers={'Authorization': f'Token {api_key}'}\n",
    "                    )\n",
    "                if response.status_code == 200:\n",
    "                    results = response.json().get('results', [])\n",
    "                    return results[0]['plate'] if results else 'UNKNOWN'\n",
    "            except Exception as e:\n",
    "                time.sleep(2)\n",
    "        return 'UNKNOWN'\n",
    "\n",
    "    def generate_output(self):\n",
    "        output_data = {\n",
    "            'redlight_intervals': self.red_light_intervals,\n",
    "            'violations': []\n",
    "        }\n",
    "        \n",
    "        for track_id, data in self.tracking_summary.items():\n",
    "            output_data['violations'].append({\n",
    "                'track_id': track_id,\n",
    "                'plate_number': data['plate_number'],\n",
    "                'first_seen': data['first_seen'],\n",
    "                'last_seen': data['last_seen'],\n",
    "                'duration': (data['last_seen'] - data['first_seen'])/self.config['output_fps']\n",
    "            })\n",
    "        \n",
    "        with open(self.config['json_output'], 'w') as f:\n",
    "            json.dump(output_data, f, indent=2)\n",
    "\n",
    "# %% [code]\n",
    "# Configuration\n",
    "config = {\n",
    "    \"input_video\": \"./vid11_27_7_FaisalTown.mp4\",\n",
    "    \"output_video\": \"./Results/final_output.mp4\",\n",
    "    \"output_folder\": \"./violationClips\",\n",
    "    \"json_output\": \"./Results/violations.json\",\n",
    "    \"output_fps\": 25,\n",
    "    \"plate_api_key\": \"df9ea40d34e80d6149f57d04d8b1328d61920916\",\n",
    "    \"histogram_files\": {\n",
    "        \"Green\": \"./Histogram_Data/averaged_hist_Green.pkl\",\n",
    "        \"Red\": \"./Histogram_Data/averaged_hist_Red.pkl\",\n",
    "        \"Orange\": \"./Histogram_Data/averaged_hist_Orange.pkl\",\n",
    "        \"None\": \"./Histogram_Data/averaged_hist_None.pkl\"\n",
    "    },\n",
    "    \"traffic_light_bbox\": (0.485879, 0.577487, 0.016630, 0.051067),\n",
    "    \"violation_zone_bbox\": (0.901061, 0.730515, 0.197877, 0.199434)\n",
    "}\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(config['output_folder'], exist_ok=True)\n",
    "\n",
    "# Run the system\n",
    "system = TrafficViolationSystem(config)\n",
    "system.process_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code by Saim for clipping videos  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from ultralytics import YOLO  # Assuming YOLOv8 is installed and available\n",
    "\n",
    "\n",
    "def load_histogram(file_path):\n",
    "    \"\"\"Load a histogram from a pickle file.\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        histogram = pickle.load(file)\n",
    "    return histogram\n",
    "\n",
    "\n",
    "def calculate_histogram(image, bbox):\n",
    "    \"\"\"Calculate and normalize the histogram for a region in the image.\"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    x_center, y_center, box_width, box_height = bbox\n",
    "\n",
    "    # Convert normalized coordinates to pixel coordinates\n",
    "    x_min = int((x_center - box_width / 2) * width)\n",
    "    x_max = int((x_center + box_width / 2) * width)\n",
    "    y_min = int((y_center - box_height / 2) * height)\n",
    "    y_max = int((y_center + box_height / 2) * height)\n",
    "\n",
    "    # Crop the region of interest\n",
    "    roi = image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    # Calculate the histogram\n",
    "    histogram = cv2.calcHist([roi], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    histogram = cv2.normalize(histogram, histogram).flatten()\n",
    "    return histogram\n",
    "\n",
    "\n",
    "def compare_histograms(frame_histogram, histograms):\n",
    "    \"\"\"Compare the frame histogram with a list of histograms using correlation.\"\"\"\n",
    "    best_match = None\n",
    "    best_score = -1\n",
    "\n",
    "    for label, histogram in histograms.items():\n",
    "        score = cv2.compareHist(frame_histogram, histogram, cv2.HISTCMP_CORREL)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = label\n",
    "\n",
    "    return best_match, best_score\n",
    "\n",
    "\n",
    "def draw_arrow(frame, x1, y1, x2, y2):\n",
    "    \"\"\"Draw a large, filled downward arrow above the detected object.\"\"\"\n",
    "    center_x = (x1 + x2) // 2\n",
    "    top_y = y1 - 150  # Position above the bounding box\n",
    "\n",
    "    # Define arrow dimensions\n",
    "    arrow_width = 50\n",
    "    arrow_height = 100\n",
    "    shaft_width = 20\n",
    "\n",
    "    # Coordinates for the arrowhead\n",
    "    arrow_tip = (center_x, y1)\n",
    "    left_corner = (center_x - arrow_width, top_y + arrow_height)\n",
    "    right_corner = (center_x + arrow_width, top_y + arrow_height)\n",
    "\n",
    "    # Coordinates for the shaft\n",
    "    shaft_top_left = (center_x - shaft_width, top_y)\n",
    "    shaft_top_right = (center_x + shaft_width, top_y)\n",
    "    shaft_bottom_left = (center_x - shaft_width, top_y + arrow_height)\n",
    "    shaft_bottom_right = (center_x + shaft_width, top_y + arrow_height)\n",
    "\n",
    "    # Combine polygons to form the arrow\n",
    "    arrow_head = np.array([arrow_tip, left_corner, right_corner], np.int32)\n",
    "    arrow_shaft = np.array([shaft_top_left, shaft_bottom_left, shaft_bottom_right, shaft_top_right], np.int32)\n",
    "\n",
    "    # Draw the filled polygons\n",
    "    color = (0, 0, 255)  # Red color for the arrow\n",
    "    cv2.fillPoly(frame, [arrow_head], color)\n",
    "    cv2.fillPoly(frame, [arrow_shaft], color)\n",
    "\n",
    "\n",
    "def detect_cars(frame, model, specified_path):\n",
    "    \"\"\"Detect cars only within the specified path region.\"\"\"\n",
    "    results = model(frame)  # Perform inference\n",
    "    detections = []\n",
    "\n",
    "    for box in results[0].boxes.data:  # Access bounding box data\n",
    "        x_min, y_min, x_max, y_max = map(int, box[:4])  # Extract coordinates\n",
    "        cls = int(box[5])  # Class ID\n",
    "        if cls == 2:  # Class ID for 'car'\n",
    "            # Check if the bounding box lies within the specified path\n",
    "            car_center_x = (x_min + x_max) // 2\n",
    "            car_center_y = (y_min + y_max) // 2\n",
    "            if is_within_path(car_center_x, car_center_y, specified_path, frame.shape):\n",
    "                detections.append((x_min, y_min, x_max, y_max))\n",
    "                draw_arrow(frame, x_min, y_min, x_max, y_max)  # Draw arrow on the car\n",
    "    return detections\n",
    "\n",
    "\n",
    "def is_within_path(car_center_x, car_center_y, path_bbox, frame_shape):\n",
    "    \"\"\"Check if the car's center lies within the specified path.\"\"\"\n",
    "    height, width, _ = frame_shape\n",
    "    x_center, y_center, box_width, box_height = path_bbox\n",
    "\n",
    "    # Convert normalized path coordinates to pixel coordinates\n",
    "    x_min = int((x_center - box_width / 2) * width)\n",
    "    x_max = int((x_center + box_width / 2) * width)\n",
    "    y_min = int((y_center - box_height / 2) * height)\n",
    "    y_max = int((y_center + box_height / 2) * height)\n",
    "\n",
    "    return x_min <= car_center_x <= x_max and y_min <= car_center_y <= y_max\n",
    "\n",
    "\n",
    "def process_video(input_video_path, histogram_files, bbox, path_bbox, output_video_path, save_frames=False, temp_frame_folder=None):\n",
    "    \"\"\"\n",
    "    Process video, match histograms, detect cars, and output processed video.\n",
    "    Only frames with a \"Red\" signal are written to the output video.\n",
    "    \"\"\"\n",
    "    # Load the precomputed histograms\n",
    "    histograms = {label: load_histogram(file) for label, file in histogram_files.items()}\n",
    "\n",
    "    # Initialize YOLO model\n",
    "    model = YOLO('yolov8n.pt')  # Use YOLOv8 pretrained model\n",
    "\n",
    "    # Open the input video\n",
    "    video_cap = cv2.VideoCapture(input_video_path)\n",
    "    fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Set up the video writer for only the red-signal frames\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    frame_count = 0\n",
    "    saved_frame_count = 0\n",
    "\n",
    "    while video_cap.isOpened():\n",
    "        ret, frame = video_cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Calculate the histogram for the specified region\n",
    "        frame_histogram = calculate_histogram(frame, bbox)\n",
    "\n",
    "        # Compare histograms to determine the signal color\n",
    "        matched_label, score = compare_histograms(frame_histogram, histograms)\n",
    "\n",
    "        # Draw the bounding box for the region where histogram is calculated\n",
    "        height, width, _ = frame.shape\n",
    "        x_center, y_center, box_width, box_height = bbox\n",
    "        x_min = int((x_center - box_width / 2) * width)\n",
    "        x_max = int((x_center + box_width / 2) * width)\n",
    "        y_min = int((y_center - box_height / 2) * height)\n",
    "        y_max = int((y_center + box_height / 2) * height)\n",
    "\n",
    "        # Color mapping for visualization (optional)\n",
    "        color_map = {\n",
    "            \"Green\": (0, 255, 0),\n",
    "            \"None\": (255, 255, 255),\n",
    "            \"Orange\": (0, 165, 255),\n",
    "            \"Red\": (0, 0, 255)\n",
    "        }\n",
    "        color = color_map.get(matched_label, (255, 255, 255))  # Default to white if label not found\n",
    "        cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "        label_text = f\"{matched_label} ({score:.2f})\"\n",
    "        cv2.putText(frame, label_text, (x_min, y_max + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        # Only process and save the frame if the signal is \"Red\"\n",
    "        if matched_label == \"Red\":\n",
    "            # Detect cars in the frame\n",
    "            car_detections = detect_cars(frame, model, path_bbox)\n",
    "            for (x1, y1, x2, y2) in car_detections:\n",
    "                # Car detections already include the arrow drawing, but drawing the bounding box again if desired\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Red for car detections\n",
    "\n",
    "            # Optionally save frames as images\n",
    "            if save_frames and temp_frame_folder:\n",
    "                os.makedirs(temp_frame_folder, exist_ok=True)\n",
    "                temp_frame_path = os.path.join(temp_frame_folder, f\"frame_{frame_count:04d}.jpg\")\n",
    "                cv2.imwrite(temp_frame_path, frame)\n",
    "\n",
    "            # Write the processed frame to the output video clip\n",
    "            video_writer.write(frame)\n",
    "            saved_frame_count += 1\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    video_cap.release()\n",
    "    video_writer.release()\n",
    "    print(f\"Processed video clip saved at {output_video_path}\")\n",
    "    print(f\"Total frames processed: {frame_count}, Frames saved: {saved_frame_count}\")\n",
    "\n",
    "\n",
    "# Inputs\n",
    "input_video_path = './vid11_27_7_FaisalTown.mp4'  # Input video path\n",
    "histogram_files = {\n",
    "    \"Green\": \"./Histogram_Data/averaged_hist_Green.pkl\",\n",
    "    \"Red\": \"./Histogram_Data/averaged_hist_Red.pkl\",\n",
    "    \"Orange\": \"./Histogram_Data/averaged_hist_Orange.pkl\",\n",
    "    \"None\": \"./Histogram_Data/averaged_hist_None.pkl\"\n",
    "}\n",
    "bbox = (0.485879, 0.577487, 0.016630, 0.051067)  # Normalized coordinates for histogram calculation\n",
    "path_bbox = (0.901061, 0.730515, 0.197877, 0.199434)  # New specified path coordinates for car detection\n",
    "output_video_path = './violationClips/output_red_clip_video.mp4'  # Output video path for red-signal clip\n",
    "\n",
    "# Process video and save only red-signal frames as a clip\n",
    "process_video(input_video_path, histogram_files, bbox, path_bbox, output_video_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradio code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* Running on public URL: https://20467e26444be67412.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://20467e26444be67412.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 11 persons, 9 cars, 5 motorcycles, 1 truck, 80.4ms\n",
      "Speed: 6.2ms preprocess, 80.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 9 cars, 3 motorcycles, 1 truck, 80.8ms\n",
      "Speed: 6.5ms preprocess, 80.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 10 cars, 5 motorcycles, 169.4ms\n",
      "Speed: 4.3ms preprocess, 169.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 11 cars, 3 motorcycles, 112.3ms\n",
      "Speed: 3.9ms preprocess, 112.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 7 cars, 3 motorcycles, 178.3ms\n",
      "Speed: 4.1ms preprocess, 178.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 9 cars, 3 motorcycles, 182.6ms\n",
      "Speed: 10.7ms preprocess, 182.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 7 cars, 3 motorcycles, 1 truck, 91.2ms\n",
      "Speed: 5.3ms preprocess, 91.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 9 cars, 2 motorcycles, 1 truck, 135.9ms\n",
      "Speed: 2.3ms preprocess, 135.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 7 cars, 2 motorcycles, 2 trucks, 82.7ms\n",
      "Speed: 3.2ms preprocess, 82.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 7 cars, 5 motorcycles, 2 trucks, 102.6ms\n",
      "Speed: 4.7ms preprocess, 102.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 8 cars, 4 motorcycles, 1 truck, 224.2ms\n",
      "Speed: 6.1ms preprocess, 224.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 7 cars, 3 motorcycles, 1 truck, 152.9ms\n",
      "Speed: 12.1ms preprocess, 152.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 7 cars, 2 motorcycles, 123.4ms\n",
      "Speed: 2.6ms preprocess, 123.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 8 cars, 2 motorcycles, 78.7ms\n",
      "Speed: 2.8ms preprocess, 78.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 8 cars, 2 motorcycles, 82.0ms\n",
      "Speed: 3.1ms preprocess, 82.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 7 cars, 1 motorcycle, 114.7ms\n",
      "Speed: 3.7ms preprocess, 114.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 6 cars, 1 motorcycle, 124.6ms\n",
      "Speed: 3.5ms preprocess, 124.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 6 cars, 3 motorcycles, 194.9ms\n",
      "Speed: 3.6ms preprocess, 194.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 6 cars, 2 motorcycles, 83.8ms\n",
      "Speed: 4.2ms preprocess, 83.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 6 cars, 1 motorcycle, 71.5ms\n",
      "Speed: 3.6ms preprocess, 71.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 6 cars, 1 motorcycle, 81.6ms\n",
      "Speed: 2.8ms preprocess, 81.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 6 cars, 1 motorcycle, 207.5ms\n",
      "Speed: 4.0ms preprocess, 207.5ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 5 cars, 2 motorcycles, 155.3ms\n",
      "Speed: 7.5ms preprocess, 155.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 5 cars, 2 motorcycles, 157.0ms\n",
      "Speed: 5.6ms preprocess, 157.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 5 cars, 3 motorcycles, 84.2ms\n",
      "Speed: 4.5ms preprocess, 84.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 4 cars, 2 motorcycles, 83.2ms\n",
      "Speed: 2.9ms preprocess, 83.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 5 cars, 1 motorcycle, 168.4ms\n",
      "Speed: 3.3ms preprocess, 168.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 6 cars, 2 motorcycles, 103.6ms\n",
      "Speed: 3.9ms preprocess, 103.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 7 cars, 1 motorcycle, 104.0ms\n",
      "Speed: 4.0ms preprocess, 104.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 5 cars, 1 motorcycle, 108.8ms\n",
      "Speed: 13.4ms preprocess, 108.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 5 cars, 1 motorcycle, 103.0ms\n",
      "Speed: 6.6ms preprocess, 103.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 6 cars, 1 motorcycle, 173.9ms\n",
      "Speed: 7.6ms preprocess, 173.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 6 cars, 100.1ms\n",
      "Speed: 2.8ms preprocess, 100.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 7 cars, 107.6ms\n",
      "Speed: 3.3ms preprocess, 107.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 9 cars, 83.5ms\n",
      "Speed: 3.6ms preprocess, 83.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 9 cars, 81.2ms\n",
      "Speed: 3.6ms preprocess, 81.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 9 cars, 1 truck, 160.1ms\n",
      "Speed: 2.9ms preprocess, 160.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 9 cars, 1 motorcycle, 101.9ms\n",
      "Speed: 2.1ms preprocess, 101.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 8 cars, 2 motorcycles, 95.3ms\n",
      "Speed: 5.1ms preprocess, 95.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 9 cars, 1 motorcycle, 1 truck, 97.4ms\n",
      "Speed: 3.7ms preprocess, 97.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 8 cars, 1 motorcycle, 1 truck, 95.6ms\n",
      "Speed: 3.2ms preprocess, 95.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 9 cars, 2 motorcycles, 1 truck, 145.8ms\n",
      "Speed: 3.9ms preprocess, 145.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 10 cars, 1 motorcycle, 1 truck, 101.8ms\n",
      "Speed: 3.7ms preprocess, 101.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 9 cars, 1 motorcycle, 1 truck, 117.5ms\n",
      "Speed: 2.2ms preprocess, 117.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 11 cars, 1 motorcycle, 2 trucks, 116.3ms\n",
      "Speed: 3.3ms preprocess, 116.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 10 cars, 1 motorcycle, 2 trucks, 101.6ms\n",
      "Speed: 3.4ms preprocess, 101.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 11 cars, 2 motorcycles, 2 trucks, 183.8ms\n",
      "Speed: 2.9ms preprocess, 183.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 11 cars, 1 motorcycle, 2 trucks, 88.4ms\n",
      "Speed: 4.2ms preprocess, 88.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 12 cars, 2 motorcycles, 2 trucks, 99.2ms\n",
      "Speed: 3.2ms preprocess, 99.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 9 cars, 2 motorcycles, 1 truck, 141.7ms\n",
      "Speed: 6.1ms preprocess, 141.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 7 cars, 1 truck, 113.0ms\n",
      "Speed: 3.6ms preprocess, 113.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 9 cars, 2 motorcycles, 2 trucks, 163.4ms\n",
      "Speed: 3.3ms preprocess, 163.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 8 cars, 2 trucks, 75.4ms\n",
      "Speed: 2.4ms preprocess, 75.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 8 cars, 2 motorcycles, 2 trucks, 92.6ms\n",
      "Speed: 3.2ms preprocess, 92.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 8 cars, 2 motorcycles, 1 truck, 88.8ms\n",
      "Speed: 3.5ms preprocess, 88.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 8 cars, 1 motorcycle, 1 truck, 137.1ms\n",
      "Speed: 8.1ms preprocess, 137.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 5 cars, 3 motorcycles, 1 truck, 130.5ms\n",
      "Speed: 4.5ms preprocess, 130.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 7 cars, 2 motorcycles, 1 truck, 176.5ms\n",
      "Speed: 13.6ms preprocess, 176.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 7 cars, 2 motorcycles, 2 trucks, 119.6ms\n",
      "Speed: 4.8ms preprocess, 119.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 9 cars, 1 motorcycle, 1 truck, 121.7ms\n",
      "Speed: 3.0ms preprocess, 121.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 6 cars, 1 truck, 146.4ms\n",
      "Speed: 4.1ms preprocess, 146.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 7 cars, 1 truck, 207.0ms\n",
      "Speed: 4.6ms preprocess, 207.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 7 cars, 1 truck, 103.2ms\n",
      "Speed: 4.6ms preprocess, 103.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 7 cars, 1 truck, 116.7ms\n",
      "Speed: 3.7ms preprocess, 116.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 8 cars, 1 truck, 96.7ms\n",
      "Speed: 3.4ms preprocess, 96.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 8 cars, 1 bus, 134.2ms\n",
      "Speed: 5.0ms preprocess, 134.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 8 cars, 1 bus, 121.9ms\n",
      "Speed: 3.1ms preprocess, 121.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 7 cars, 1 bus, 1 truck, 210.9ms\n",
      "Speed: 12.8ms preprocess, 210.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 8 cars, 1 bus, 1 truck, 98.6ms\n",
      "Speed: 2.0ms preprocess, 98.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 8 cars, 1 truck, 76.1ms\n",
      "Speed: 3.8ms preprocess, 76.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 9 cars, 1 truck, 110.1ms\n",
      "Speed: 2.8ms preprocess, 110.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 8 cars, 1 truck, 90.4ms\n",
      "Speed: 7.4ms preprocess, 90.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 5 cars, 1 truck, 136.4ms\n",
      "Speed: 3.4ms preprocess, 136.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 6 cars, 1 truck, 87.2ms\n",
      "Speed: 2.6ms preprocess, 87.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 6 cars, 1 truck, 88.1ms\n",
      "Speed: 2.5ms preprocess, 88.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 6 cars, 1 truck, 86.5ms\n",
      "Speed: 2.7ms preprocess, 86.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 6 cars, 1 truck, 74.7ms\n",
      "Speed: 2.8ms preprocess, 74.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 6 cars, 1 truck, 71.9ms\n",
      "Speed: 2.6ms preprocess, 71.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 7 cars, 2 trucks, 90.9ms\n",
      "Speed: 4.1ms preprocess, 90.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 8 cars, 1 bus, 1 truck, 148.1ms\n",
      "Speed: 3.5ms preprocess, 148.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 11 cars, 1 truck, 89.8ms\n",
      "Speed: 4.0ms preprocess, 89.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 11 cars, 1 truck, 84.3ms\n",
      "Speed: 3.2ms preprocess, 84.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 8 cars, 1 truck, 76.7ms\n",
      "Speed: 3.8ms preprocess, 76.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 7 cars, 1 truck, 73.0ms\n",
      "Speed: 2.6ms preprocess, 73.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 6 cars, 1 truck, 74.4ms\n",
      "Speed: 3.5ms preprocess, 74.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 6 cars, 1 truck, 62.0ms\n",
      "Speed: 3.4ms preprocess, 62.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 6 cars, 1 truck, 156.8ms\n",
      "Speed: 3.8ms preprocess, 156.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 7 cars, 1 truck, 83.9ms\n",
      "Speed: 3.5ms preprocess, 83.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 7 cars, 1 truck, 80.3ms\n",
      "Speed: 2.8ms preprocess, 80.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 8 cars, 1 truck, 94.5ms\n",
      "Speed: 4.2ms preprocess, 94.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 8 cars, 1 truck, 107.2ms\n",
      "Speed: 4.6ms preprocess, 107.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 7 cars, 1 truck, 80.2ms\n",
      "Speed: 3.2ms preprocess, 80.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 7 cars, 1 truck, 184.6ms\n",
      "Speed: 8.2ms preprocess, 184.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 7 cars, 1 truck, 142.0ms\n",
      "Speed: 4.8ms preprocess, 142.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 8 cars, 1 truck, 144.9ms\n",
      "Speed: 4.9ms preprocess, 144.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 8 cars, 1 truck, 101.9ms\n",
      "Speed: 3.2ms preprocess, 101.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 10 cars, 2 trucks, 115.8ms\n",
      "Speed: 3.7ms preprocess, 115.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 10 cars, 1 motorcycle, 2 trucks, 158.9ms\n",
      "Speed: 3.8ms preprocess, 158.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 7 cars, 1 motorcycle, 1 truck, 115.3ms\n",
      "Speed: 5.3ms preprocess, 115.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 7 cars, 1 truck, 129.7ms\n",
      "Speed: 3.1ms preprocess, 129.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 8 cars, 2 trucks, 162.5ms\n",
      "Speed: 4.9ms preprocess, 162.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 7 cars, 1 motorcycle, 1 truck, 161.6ms\n",
      "Speed: 2.8ms preprocess, 161.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 7 cars, 1 motorcycle, 1 truck, 148.8ms\n",
      "Speed: 3.7ms preprocess, 148.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 6 cars, 1 truck, 159.4ms\n",
      "Speed: 5.8ms preprocess, 159.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 9 cars, 1 truck, 169.8ms\n",
      "Speed: 3.7ms preprocess, 169.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 8 cars, 1 truck, 142.9ms\n",
      "Speed: 4.8ms preprocess, 142.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 8 cars, 1 truck, 152.1ms\n",
      "Speed: 2.4ms preprocess, 152.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 8 cars, 1 truck, 94.9ms\n",
      "Speed: 2.7ms preprocess, 94.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 7 cars, 2 trucks, 103.7ms\n",
      "Speed: 6.3ms preprocess, 103.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 7 cars, 1 truck, 126.4ms\n",
      "Speed: 3.4ms preprocess, 126.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 8 cars, 1 motorcycle, 2 trucks, 98.7ms\n",
      "Speed: 7.2ms preprocess, 98.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 8 cars, 1 motorcycle, 1 truck, 1 skateboard, 85.7ms\n",
      "Speed: 4.0ms preprocess, 85.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 7 cars, 1 motorcycle, 1 truck, 143.3ms\n",
      "Speed: 4.0ms preprocess, 143.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 8 cars, 1 truck, 79.9ms\n",
      "Speed: 2.5ms preprocess, 79.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 7 cars, 1 motorcycle, 1 truck, 71.8ms\n",
      "Speed: 3.0ms preprocess, 71.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 bicycles, 7 cars, 1 motorcycle, 1 truck, 126.1ms\n",
      "Speed: 2.4ms preprocess, 126.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 7 cars, 1 truck, 121.9ms\n",
      "Speed: 3.5ms preprocess, 121.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 7 cars, 1 motorcycle, 1 truck, 153.0ms\n",
      "Speed: 3.4ms preprocess, 153.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 8 cars, 1 motorcycle, 1 truck, 160.8ms\n",
      "Speed: 3.5ms preprocess, 160.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 9 cars, 1 motorcycle, 1 truck, 117.2ms\n",
      "Speed: 3.7ms preprocess, 117.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 8 cars, 1 motorcycle, 1 truck, 110.3ms\n",
      "Speed: 3.9ms preprocess, 110.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 7 cars, 1 motorcycle, 1 truck, 117.3ms\n",
      "Speed: 4.7ms preprocess, 117.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 8 cars, 2 motorcycles, 1 truck, 192.4ms\n",
      "Speed: 4.0ms preprocess, 192.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 7 cars, 3 motorcycles, 1 truck, 90.4ms\n",
      "Speed: 3.2ms preprocess, 90.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 8 cars, 1 motorcycle, 1 truck, 91.7ms\n",
      "Speed: 2.7ms preprocess, 91.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 9 cars, 2 motorcycles, 1 truck, 113.1ms\n",
      "Speed: 3.8ms preprocess, 113.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 9 cars, 3 motorcycles, 1 truck, 118.8ms\n",
      "Speed: 4.3ms preprocess, 118.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 10 cars, 3 motorcycles, 1 truck, 180.8ms\n",
      "Speed: 3.7ms preprocess, 180.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 10 cars, 2 motorcycles, 1 truck, 99.5ms\n",
      "Speed: 3.6ms preprocess, 99.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 9 cars, 2 motorcycles, 1 truck, 104.8ms\n",
      "Speed: 4.5ms preprocess, 104.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 7 cars, 2 motorcycles, 1 truck, 89.5ms\n",
      "Speed: 4.8ms preprocess, 89.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 8 cars, 2 motorcycles, 1 truck, 146.9ms\n",
      "Speed: 2.7ms preprocess, 146.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 10 cars, 3 motorcycles, 2 trucks, 190.7ms\n",
      "Speed: 6.3ms preprocess, 190.7ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 7 cars, 2 motorcycles, 2 trucks, 108.4ms\n",
      "Speed: 3.1ms preprocess, 108.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 8 cars, 2 motorcycles, 2 trucks, 136.3ms\n",
      "Speed: 3.8ms preprocess, 136.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 7 cars, 2 motorcycles, 1 truck, 114.5ms\n",
      "Speed: 12.1ms preprocess, 114.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 8 cars, 3 motorcycles, 1 truck, 127.6ms\n",
      "Speed: 5.4ms preprocess, 127.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 7 cars, 3 motorcycles, 1 truck, 211.8ms\n",
      "Speed: 5.9ms preprocess, 211.8ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 9 cars, 3 motorcycles, 1 truck, 137.5ms\n",
      "Speed: 7.1ms preprocess, 137.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 9 cars, 2 motorcycles, 1 truck, 120.3ms\n",
      "Speed: 3.7ms preprocess, 120.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 8 cars, 3 motorcycles, 1 truck, 129.2ms\n",
      "Speed: 3.4ms preprocess, 129.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 9 cars, 3 motorcycles, 1 truck, 150.9ms\n",
      "Speed: 9.1ms preprocess, 150.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 8 cars, 4 motorcycles, 1 truck, 210.0ms\n",
      "Speed: 4.0ms preprocess, 210.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 7 cars, 2 motorcycles, 1 truck, 78.5ms\n",
      "Speed: 3.6ms preprocess, 78.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 6 cars, 2 motorcycles, 1 truck, 114.5ms\n",
      "Speed: 5.4ms preprocess, 114.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 5 cars, 2 motorcycles, 1 truck, 77.2ms\n",
      "Speed: 3.8ms preprocess, 77.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 5 cars, 3 motorcycles, 1 truck, 77.1ms\n",
      "Speed: 3.3ms preprocess, 77.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 5 cars, 3 motorcycles, 1 truck, 144.7ms\n",
      "Speed: 3.5ms preprocess, 144.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 7 cars, 2 motorcycles, 1 truck, 103.6ms\n",
      "Speed: 2.2ms preprocess, 103.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 6 cars, 3 motorcycles, 2 trucks, 70.4ms\n",
      "Speed: 2.6ms preprocess, 70.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 7 cars, 3 motorcycles, 2 trucks, 72.3ms\n",
      "Speed: 3.0ms preprocess, 72.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 6 cars, 3 motorcycles, 1 truck, 81.0ms\n",
      "Speed: 3.6ms preprocess, 81.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 7 cars, 3 motorcycles, 1 truck, 190.3ms\n",
      "Speed: 3.5ms preprocess, 190.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 6 cars, 3 motorcycles, 2 trucks, 98.4ms\n",
      "Speed: 3.8ms preprocess, 98.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 8 cars, 3 motorcycles, 1 truck, 85.6ms\n",
      "Speed: 3.3ms preprocess, 85.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 8 cars, 3 motorcycles, 1 truck, 100.2ms\n",
      "Speed: 4.1ms preprocess, 100.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 8 cars, 3 motorcycles, 84.9ms\n",
      "Speed: 2.0ms preprocess, 84.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 8 cars, 3 motorcycles, 133.4ms\n",
      "Speed: 2.8ms preprocess, 133.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 8 cars, 3 motorcycles, 1 truck, 117.4ms\n",
      "Speed: 4.3ms preprocess, 117.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 8 cars, 3 motorcycles, 99.3ms\n",
      "Speed: 7.5ms preprocess, 99.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 8 cars, 3 motorcycles, 85.2ms\n",
      "Speed: 4.2ms preprocess, 85.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 8 cars, 2 motorcycles, 110.7ms\n",
      "Speed: 4.6ms preprocess, 110.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 8 cars, 3 motorcycles, 133.1ms\n",
      "Speed: 4.9ms preprocess, 133.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 7 cars, 3 motorcycles, 1 truck, 117.9ms\n",
      "Speed: 4.4ms preprocess, 117.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 7 cars, 3 motorcycles, 1 truck, 88.7ms\n",
      "Speed: 3.7ms preprocess, 88.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 6 cars, 2 motorcycles, 1 truck, 85.5ms\n",
      "Speed: 2.8ms preprocess, 85.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 9 cars, 3 motorcycles, 1 truck, 95.9ms\n",
      "Speed: 3.8ms preprocess, 95.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 6 cars, 4 motorcycles, 1 truck, 169.4ms\n",
      "Speed: 2.9ms preprocess, 169.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 6 cars, 3 motorcycles, 1 truck, 110.5ms\n",
      "Speed: 2.6ms preprocess, 110.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 7 cars, 3 motorcycles, 1 truck, 148.1ms\n",
      "Speed: 6.3ms preprocess, 148.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 9 cars, 3 motorcycles, 1 truck, 125.3ms\n",
      "Speed: 2.4ms preprocess, 125.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 6 cars, 4 motorcycles, 1 truck, 115.4ms\n",
      "Speed: 3.5ms preprocess, 115.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 7 cars, 3 motorcycles, 1 truck, 156.3ms\n",
      "Speed: 5.1ms preprocess, 156.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 6 cars, 4 motorcycles, 1 truck, 89.5ms\n",
      "Speed: 4.0ms preprocess, 89.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 7 cars, 4 motorcycles, 70.8ms\n",
      "Speed: 3.2ms preprocess, 70.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 6 cars, 6 motorcycles, 87.8ms\n",
      "Speed: 6.4ms preprocess, 87.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 7 cars, 6 motorcycles, 92.0ms\n",
      "Speed: 3.0ms preprocess, 92.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "import gradio as gr\n",
    "from ultralytics import YOLO  # Assuming YOLOv8 is installed and available\n",
    "\n",
    "# Load histogram from a pickle file\n",
    "def load_histogram(file_path):\n",
    "    \"\"\"Load a histogram from a pickle file.\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        histogram = pickle.load(file)\n",
    "    return histogram\n",
    "\n",
    "# Calculate histogram for a region in the image\n",
    "def calculate_histogram(image, bbox):\n",
    "    \"\"\"Calculate and normalize the histogram for a region in the image.\"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    x_center, y_center, box_width, box_height = bbox\n",
    "\n",
    "    # Convert normalized coordinates to pixel coordinates\n",
    "    x_min = int((x_center - box_width / 2) * width)\n",
    "    x_max = int((x_center + box_width / 2) * width)\n",
    "    y_min = int((y_center - box_height / 2) * height)\n",
    "    y_max = int((y_center + box_height / 2) * height)\n",
    "\n",
    "    # Crop the region of interest\n",
    "    roi = image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    # Calculate the histogram\n",
    "    histogram = cv2.calcHist([roi], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    histogram = cv2.normalize(histogram, histogram).flatten()\n",
    "    return histogram\n",
    "\n",
    "# Compare histograms to determine the signal color\n",
    "def compare_histograms(frame_histogram, histograms):\n",
    "    \"\"\"Compare the frame histogram with a list of histograms using correlation.\"\"\"\n",
    "    best_match = None\n",
    "    best_score = -1\n",
    "\n",
    "    for label, histogram in histograms.items():\n",
    "        score = cv2.compareHist(frame_histogram, histogram, cv2.HISTCMP_CORREL)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = label\n",
    "\n",
    "    return best_match, best_score\n",
    "\n",
    "# Draw a large, filled downward arrow above the detected object\n",
    "def draw_arrow(frame, x1, y1, x2, y2):\n",
    "    \"\"\"Draw a large, filled downward arrow above the detected object.\"\"\"\n",
    "    center_x = (x1 + x2) // 2\n",
    "    top_y = y1 - 150  # Position above the bounding box\n",
    "\n",
    "    # Define arrow dimensions\n",
    "    arrow_width = 50\n",
    "    arrow_height = 100\n",
    "    shaft_width = 20\n",
    "\n",
    "    # Coordinates for the arrowhead\n",
    "    arrow_tip = (center_x, y1)\n",
    "    left_corner = (center_x - arrow_width, top_y + arrow_height)\n",
    "    right_corner = (center_x + arrow_width, top_y + arrow_height)\n",
    "\n",
    "    # Coordinates for the shaft\n",
    "    shaft_top_left = (center_x - shaft_width, top_y)\n",
    "    shaft_top_right = (center_x + shaft_width, top_y)\n",
    "    shaft_bottom_left = (center_x - shaft_width, top_y + arrow_height)\n",
    "    shaft_bottom_right = (center_x + shaft_width, top_y + arrow_height)\n",
    "\n",
    "    # Combine polygons to form the arrow\n",
    "    arrow_head = np.array([arrow_tip, left_corner, right_corner], np.int32)\n",
    "    arrow_shaft = np.array([shaft_top_left, shaft_bottom_left, shaft_bottom_right, shaft_top_right], np.int32)\n",
    "\n",
    "    # Draw the filled polygons\n",
    "    color = (0, 0, 255)  # Red color for the arrow\n",
    "    cv2.fillPoly(frame, [arrow_head], color)\n",
    "    cv2.fillPoly(frame, [arrow_shaft], color)\n",
    "\n",
    "# Detect cars within the specified path region\n",
    "def detect_cars(frame, model, specified_path):\n",
    "    \"\"\"Detect cars only within the specified path region.\"\"\"\n",
    "    results = model(frame)  # Perform inference\n",
    "    detections = []\n",
    "\n",
    "    for box in results[0].boxes.data:  # Access bounding box data\n",
    "        x_min, y_min, x_max, y_max = map(int, box[:4])  # Extract coordinates\n",
    "        cls = int(box[5])  # Class ID\n",
    "        if cls == 2:  # Class ID for 'car'\n",
    "            # Check if the bounding box lies within the specified path\n",
    "            car_center_x = (x_min + x_max) // 2\n",
    "            car_center_y = (y_min + y_max) // 2\n",
    "            if is_within_path(car_center_x, car_center_y, specified_path, frame.shape):\n",
    "                detections.append((x_min, y_min, x_max, y_max))\n",
    "                draw_arrow(frame, x_min, y_min, x_max, y_max)  # Draw arrow on the car\n",
    "    return detections\n",
    "\n",
    "# Check if a car's center lies within the specified path\n",
    "def is_within_path(car_center_x, car_center_y, path_bbox, frame_shape):\n",
    "    \"\"\"Check if the car's center lies within the specified path.\"\"\"\n",
    "    height, width, _ = frame_shape\n",
    "    x_center, y_center, box_width, box_height = path_bbox\n",
    "\n",
    "    # Convert normalized path coordinates to pixel coordinates\n",
    "    x_min = int((x_center - box_width / 2) * width)\n",
    "    x_max = int((x_center + box_width / 2) * width)\n",
    "    y_min = int((y_center - box_height / 2) * height)\n",
    "    y_max = int((y_center + box_height / 2) * height)\n",
    "\n",
    "    return x_min <= car_center_x <= x_max and y_min <= car_center_y <= y_max\n",
    "\n",
    "# Process video and generate output\n",
    "def process_video(input_video_path, histogram_files, bbox, path_bbox, output_video_path):\n",
    "    \"\"\"\n",
    "    Process video, match histograms, detect cars, and output processed video.\n",
    "    Only frames with a \"Red\" signal are written to the output video.\n",
    "    \"\"\"\n",
    "    # Load the precomputed histograms\n",
    "    histograms = {label: load_histogram(file) for label, file in histogram_files.items()}\n",
    "\n",
    "    # Initialize YOLO model\n",
    "    model = YOLO('yolov8n.pt')  # Use YOLOv8 pretrained model\n",
    "\n",
    "    # Open the input video\n",
    "    video_cap = cv2.VideoCapture(input_video_path)\n",
    "    fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Set up the video writer for only the red-signal frames\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    frame_count = 0\n",
    "    saved_frame_count = 0\n",
    "\n",
    "    while video_cap.isOpened():\n",
    "        ret, frame = video_cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Calculate the histogram for the specified region\n",
    "        frame_histogram = calculate_histogram(frame, bbox)\n",
    "\n",
    "        # Compare histograms to determine the signal color\n",
    "        matched_label, score = compare_histograms(frame_histogram, histograms)\n",
    "\n",
    "        # Draw the bounding box for the region where histogram is calculated\n",
    "        height, width, _ = frame.shape\n",
    "        x_center, y_center, box_width, box_height = bbox\n",
    "        x_min = int((x_center - box_width / 2) * width)\n",
    "        x_max = int((x_center + box_width / 2) * width)\n",
    "        y_min = int((y_center - box_height / 2) * height)\n",
    "        y_max = int((y_center + box_height / 2) * height)\n",
    "\n",
    "        # Color mapping for visualization\n",
    "        color_map = {\n",
    "            \"Green\": (0, 255, 0),\n",
    "            \"None\": (255, 255, 255),\n",
    "            \"Orange\": (0, 165, 255),\n",
    "            \"Red\": (0, 0, 255)\n",
    "        }\n",
    "        color = color_map.get(matched_label, (255, 255, 255))  # Default to white if label not found\n",
    "        cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "        label_text = f\"{matched_label} ({score:.2f})\"\n",
    "        cv2.putText(frame, label_text, (x_min, y_max + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        # Only process and save the frame if the signal is \"Red\"\n",
    "        if matched_label == \"Red\":\n",
    "            # Detect cars in the frame\n",
    "            car_detections = detect_cars(frame, model, path_bbox)\n",
    "            for (x1, y1, x2, y2) in car_detections:\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Red for car detections\n",
    "\n",
    "            # Write the processed frame to the output video clip\n",
    "            video_writer.write(frame)\n",
    "            saved_frame_count += 1\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    video_cap.release()\n",
    "    video_writer.release()\n",
    "    print(f\"Processed video clip saved at {output_video_path}\")\n",
    "    print(f\"Total frames processed: {frame_count}, Frames saved: {saved_frame_count}\")\n",
    "\n",
    "# Gradio wrapper function\n",
    "def gradio_process_video(input_video):\n",
    "    \"\"\"Wrapper function for Gradio interface.\"\"\"\n",
    "    # Define the output video path\n",
    "    output_video_path = \"./red_output_video.mp4\"\n",
    "    \n",
    "    # Define parameters\n",
    "    histogram_files = {\n",
    "        \"Green\": \"./Histogram_Data/averaged_hist_Green.pkl\",\n",
    "        \"Red\": \"./Histogram_Data/averaged_hist_Red.pkl\",\n",
    "        \"Orange\": \"./Histogram_Data/averaged_hist_Orange.pkl\",\n",
    "        \"None\": \"./Histogram_Data/averaged_hist_None.pkl\"\n",
    "    }\n",
    "    bbox = (0.485879, 0.577487, 0.016630, 0.051067)  # Normalized coordinates for histogram calculation\n",
    "    path_bbox = (0.901061, 0.730515, 0.197877, 0.199434)  # Path coordinates for car detection\n",
    "\n",
    "    # Process the video\n",
    "    process_video(\n",
    "        input_video_path=input_video,\n",
    "        histogram_files=histogram_files,\n",
    "        bbox=bbox,\n",
    "        path_bbox=path_bbox,\n",
    "        output_video_path=output_video_path\n",
    "    )\n",
    "    \n",
    "    return output_video_path\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks(title=\"Automatic Traffic Violation Detection\") as demo:\n",
    "    gr.Markdown(\"#  Automatic Traffic Violation Detection System\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            input_video = gr.Video(label=\"Upload Traffic Video\", sources=[\"upload\"])\n",
    "            process_btn = gr.Button(\"Detect Violations\", variant=\"primary\")\n",
    "        \n",
    "        with gr.Column():\n",
    "            output_video = gr.Video(label=\"Violations Clip (Red Light Period)\", autoplay=True)\n",
    "    \n",
    "    process_btn.click(\n",
    "        fn=gradio_process_video,\n",
    "        inputs=[input_video],\n",
    "        outputs=[output_video],\n",
    "        \n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(\n",
    "        share = True\n",
    "    )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
