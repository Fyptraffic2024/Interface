{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title Part1\n",
        "!pip install ultralytics\n",
        "\n",
        "!git clone https://github.com/abewley/sort\n",
        "\n",
        "%cd /content/sort\n",
        "\n",
        "\n",
        "# Open the file in edit mode\n",
        "with open('/content/sort/sort.py', 'r+') as f:\n",
        "    content = f.read()\n",
        "    # Make the changes (replace 'TkAgg' with 'Agg')\n",
        "    content = content.replace(\"matplotlib.use('TkAgg')\", \"matplotlib.use('Agg')\")\n",
        "    # Overwrite the file with the modified content\n",
        "    f.seek(0)\n",
        "    f.write(content)\n",
        "    f.truncate()\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "!pip install filterpy\n",
        "\n",
        "# @title Arrow\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from ultralytics import YOLO  # Assuming YOLOv8 is installed and available\n",
        "\n",
        "\n",
        "def load_histogram(file_path):\n",
        "    \"\"\"Load a histogram from a pickle file.\"\"\"\n",
        "    with open(file_path, 'rb') as file:\n",
        "        histogram = pickle.load(file)\n",
        "    return histogram\n",
        "\n",
        "\n",
        "def calculate_histogram(image, bbox):\n",
        "    \"\"\"Calculate and normalize the histogram for a region in the image.\"\"\"\n",
        "    height, width, _ = image.shape\n",
        "    x_center, y_center, box_width, box_height = bbox\n",
        "\n",
        "    # Convert normalized coordinates to pixel coordinates\n",
        "    x_min = int((x_center - box_width / 2) * width)\n",
        "    x_max = int((x_center + box_width / 2) * width)\n",
        "    y_min = int((y_center - box_height / 2) * height)\n",
        "    y_max = int((y_center + box_height / 2) * height)\n",
        "\n",
        "    # Crop the region of interest\n",
        "    roi = image[y_min:y_max, x_min:x_max]\n",
        "\n",
        "    # Calculate the histogram\n",
        "    histogram = cv2.calcHist([roi], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
        "    histogram = cv2.normalize(histogram, histogram).flatten()\n",
        "    return histogram\n",
        "\n",
        "\n",
        "def compare_histograms(frame_histogram, histograms):\n",
        "    \"\"\"Compare the frame histogram with a list of histograms using correlation.\"\"\"\n",
        "    best_match = None\n",
        "    best_score = -1\n",
        "\n",
        "    for label, histogram in histograms.items():\n",
        "        score = cv2.compareHist(frame_histogram, histogram, cv2.HISTCMP_CORREL)\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_match = label\n",
        "\n",
        "    return best_match, best_score\n",
        "\n",
        "\n",
        "def draw_arrow(frame, x1, y1, x2, y2):\n",
        "    \"\"\"Draw a large, filled downward arrow above the detected object.\"\"\"\n",
        "    center_x = (x1 + x2) // 2\n",
        "    top_y = y1 - 150  # Position above the bounding box\n",
        "\n",
        "    # Define arrow dimensions\n",
        "    arrow_width = 50\n",
        "    arrow_height = 100\n",
        "    shaft_width = 20\n",
        "\n",
        "    # Coordinates for the arrowhead\n",
        "    arrow_tip = (center_x, y1)\n",
        "    left_corner = (center_x - arrow_width, top_y + arrow_height)\n",
        "    right_corner = (center_x + arrow_width, top_y + arrow_height)\n",
        "\n",
        "    # Coordinates for the shaft\n",
        "    shaft_top_left = (center_x - shaft_width, top_y)\n",
        "    shaft_top_right = (center_x + shaft_width, top_y)\n",
        "    shaft_bottom_left = (center_x - shaft_width, top_y + arrow_height)\n",
        "    shaft_bottom_right = (center_x + shaft_width, top_y + arrow_height)\n",
        "\n",
        "    # Combine polygons to form the arrow\n",
        "    arrow_head = np.array([arrow_tip, left_corner, right_corner], np.int32)\n",
        "    arrow_shaft = np.array([shaft_top_left, shaft_bottom_left, shaft_bottom_right, shaft_top_right], np.int32)\n",
        "\n",
        "    # Draw the filled polygons\n",
        "    color = (0, 0, 255)  # Red color for the arrow\n",
        "    cv2.fillPoly(frame, [arrow_head], color)\n",
        "    cv2.fillPoly(frame, [arrow_shaft], color)\n",
        "\n",
        "\n",
        "def detect_cars(frame, model, specified_path):\n",
        "    \"\"\"Detect cars only within the specified path region.\"\"\"\n",
        "    results = model(frame)  # Perform inference\n",
        "    detections = []\n",
        "\n",
        "    for box in results[0].boxes.data:  # Access bounding box data\n",
        "        x_min, y_min, x_max, y_max = map(int, box[:4])  # Extract coordinates\n",
        "        cls = int(box[5])  # Class ID\n",
        "        if cls == 2:  # Class ID for 'car'\n",
        "            # Check if the bounding box lies within the specified path\n",
        "            car_center_x = (x_min + x_max) // 2\n",
        "            car_center_y = (y_min + y_max) // 2\n",
        "            if is_within_path(car_center_x, car_center_y, specified_path, frame.shape):\n",
        "                detections.append((x_min, y_min, x_max, y_max))\n",
        "                draw_arrow(frame, x_min, y_min, x_max, y_max)  # Draw arrow on the car\n",
        "    return detections\n",
        "\n",
        "\n",
        "def is_within_path(car_center_x, car_center_y, path_bbox, frame_shape):\n",
        "    \"\"\"Check if the car's center lies within the specified path.\"\"\"\n",
        "    height, width, _ = frame_shape\n",
        "    x_center, y_center, box_width, box_height = path_bbox\n",
        "\n",
        "    # Convert normalized path coordinates to pixel coordinates\n",
        "    x_min = int((x_center - box_width / 2) * width)\n",
        "    x_max = int((x_center + box_width / 2) * width)\n",
        "    y_min = int((y_center - box_height / 2) * height)\n",
        "    y_max = int((y_center + box_height / 2) * height)\n",
        "\n",
        "    return x_min <= car_center_x <= x_max and y_min <= car_center_y <= y_max\n",
        "\n",
        "\n",
        "def process_video(input_video_path, histogram_files, bbox, path_bbox, output_video_path, save_frames=False, temp_frame_folder=None):\n",
        "    \"\"\"\n",
        "    Process video, match histograms, detect cars, and output processed video.\n",
        "    \"\"\"\n",
        "    # Load the precomputed histograms\n",
        "    histograms = {label: load_histogram(file) for label, file in histogram_files.items()}\n",
        "\n",
        "    # Initialize YOLO model\n",
        "    model = YOLO('yolov8n.pt')  # Use YOLOv8 pretrained model\n",
        "\n",
        "    # Load the input video\n",
        "    video_cap = cv2.VideoCapture(input_video_path)\n",
        "    fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
        "    frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "    frame_count = 0\n",
        "\n",
        "    while video_cap.isOpened():\n",
        "        ret, frame = video_cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Calculate the histogram for the specified region\n",
        "        frame_histogram = calculate_histogram(frame, bbox)\n",
        "\n",
        "        # Compare histograms\n",
        "        matched_label, score = compare_histograms(frame_histogram, histograms)\n",
        "\n",
        "        # Draw the bounding box on the frame for the given coordinates\n",
        "        height, width, _ = frame.shape\n",
        "        x_center, y_center, box_width, box_height = bbox\n",
        "        x_min = int((x_center - box_width / 2) * width)\n",
        "        x_max = int((x_center + box_width / 2) * width)\n",
        "        y_min = int((y_center - box_height / 2) * height)\n",
        "        y_max = int((y_center + box_height / 2) * height)\n",
        "\n",
        "        # Draw the original rectangle\n",
        "        color_map = {\n",
        "            \"Green\": (0, 255, 0),\n",
        "            \"None\": (255, 255, 255),\n",
        "            \"Orange\": (0, 165, 255),\n",
        "            \"Red\": (0, 0, 255)\n",
        "        }\n",
        "        color = color_map.get(matched_label, (255, 255, 255))  # Default to white if label not found\n",
        "        cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), color, 2)\n",
        "        label = f\"{matched_label} ({score:.2f})\"\n",
        "        cv2.putText(frame, label, (x_min, y_max + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "        # Detect cars in the frame if the label is \"Red\"\n",
        "        if matched_label == \"Red\":\n",
        "            car_detections = detect_cars(frame, model, path_bbox)\n",
        "            for (x1, y1, x2, y2) in car_detections:\n",
        "                # Car detections already include the arrow drawing\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Red for car detections\n",
        "\n",
        "        # Save frames if needed\n",
        "        if save_frames and temp_frame_folder:\n",
        "            os.makedirs(temp_frame_folder, exist_ok=True)\n",
        "            temp_frame_path = os.path.join(temp_frame_folder, f\"frame_{frame_count:04d}.jpg\")\n",
        "            cv2.imwrite(temp_frame_path, frame)\n",
        "\n",
        "        # Write the processed frame to the output video\n",
        "        video_writer.write(frame)\n",
        "        frame_count += 1\n",
        "\n",
        "    video_cap.release()\n",
        "    video_writer.release()\n",
        "    print(f\"Processed video saved at {output_video_path}\")\n",
        "\n",
        "\n",
        "# Inputs\n",
        "input_video_path = '/content/drive/MyDrive/Input_Data/vid11_27_7_FaisalTown.mp4'  # Input video path\n",
        "histogram_files = {\n",
        "    \"Green\": \"/content/drive/MyDrive/Histogram/averaged_hist_Green.pkl\",\n",
        "    \"None\": \"/content/drive/MyDrive/Histogram/averaged_hist_None.pkl\",\n",
        "    \"Orange\": \"/content/drive/MyDrive/Histogram/averaged_hist_Orange.pkl\",\n",
        "    \"Red\": \"/content/drive/MyDrive/Histogram/averaged_hist_Red.pkl\"\n",
        "}\n",
        "bbox = (0.485879, 0.577487, 0.016630, 0.051067)  # Normalized coordinates\n",
        "path_bbox = (0.901061, 0.730515, 0.197877, 0.199434)  # New specified path coordinates\n",
        "output_video_path = '/content/drive/MyDrive/Resulted_violation/output_video.mp4'  # Output video path\n",
        "\n",
        "# Process video\n",
        "process_video(input_video_path, histogram_files, bbox, path_bbox, output_video_path)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VG1NyPubsdnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title part2\n",
        "import csv\n",
        "\n",
        "import logging\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# Constants for signal status\n",
        "SIGNAL_RED = \"Red\"\n",
        "SIGNAL_GREEN = \"Green\"\n",
        "\n",
        "# List to store violation records\n",
        "violations = []\n",
        "\n",
        "upper_line_start = (1389, 699)\n",
        "upper_line_end = (1859, 666)\n",
        "lower_line_start = (1912, 842)\n",
        "lower_line_end = (1332, 1061)\n",
        "\n",
        "\n",
        "def load_histograms(file_path):\n",
        "    \"\"\"Load a histogram from a pickle file.\"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        logging.error(f\"Histogram file {file_path} not found!\")\n",
        "        return None\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            histogram = pickle.load(file)\n",
        "        return histogram\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error loading histogram from {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def calculate_histogram(image, bbox):\n",
        "    \"\"\"Calculate and normalize the histogram for a region in the image.\"\"\"\n",
        "    height, width, _ = image.shape\n",
        "    x_center, y_center, box_width, box_height = bbox\n",
        "\n",
        "    # Convert normalized coordinates to pixel coordinates\n",
        "    x_min = int((x_center - box_width / 2) * width)\n",
        "    x_max = int((x_center + box_width / 2) * width)\n",
        "    y_min = int((y_center - box_height / 2) * height)\n",
        "    y_max = int((y_center + box_height / 2) * height)\n",
        "\n",
        "    # Crop the region of interest\n",
        "    roi = image[y_min:y_max, x_min:x_max]\n",
        "\n",
        "    # Calculate the histogram\n",
        "    histogram = cv2.calcHist([roi], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
        "    histogram = cv2.normalize(histogram, histogram).flatten()\n",
        "    return histogram\n",
        "\n",
        "def compare_histograms(frame_histogram, histograms):\n",
        "    \"\"\"Compare the frame histogram with a list of histograms using correlation.\"\"\"\n",
        "    best_match = None\n",
        "    best_score = -1\n",
        "\n",
        "    for label, histogram in histograms.items():\n",
        "        score = cv2.compareHist(frame_histogram, histogram, cv2.HISTCMP_CORREL)\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_match = label\n",
        "\n",
        "    return best_match, best_score\n",
        "\n",
        "def detect_cars(frame, model, specified_path):\n",
        "    \"\"\"Detect cars only within the specified path region.\"\"\"\n",
        "    results = model(frame)  # Perform inference\n",
        "    detections = []\n",
        "\n",
        "    for box in results[0].boxes.data:  # Access bounding box data\n",
        "        x_min, y_min, x_max, y_max = map(int, box[:4])  # Extract coordinates\n",
        "        cls = int(box[5])  # Class ID\n",
        "        if cls == 2:  # Class ID for 'car'\n",
        "            # Check if the bounding box lies within the specified path\n",
        "            car_center_x = (x_min + x_max) // 2\n",
        "            car_center_y = (y_min + y_max) // 2\n",
        "            if is_within_path(car_center_x, car_center_y, specified_path, frame.shape):\n",
        "                # Ensure detections are in the correct format for the tracker: [x1, y1, x2, y2, score]\n",
        "                detections.append([x_min, y_min, x_max, y_max, box[4].item()])  # Add confidence score\n",
        "\n",
        "    # Convert detections to a NumPy array if it's not empty\n",
        "    if detections:\n",
        "        detections = np.array(detections)\n",
        "    else:\n",
        "        # Return an empty NumPy array with the correct shape if no detections are found\n",
        "        detections = np.empty((0, 5))\n",
        "    return detections\n",
        "\n",
        "def is_within_path(car_center_x, car_center_y, path_bbox, frame_shape):\n",
        "    \"\"\"Check if the car's center lies within the specified path.\"\"\"\n",
        "    height, width, _ = frame_shape\n",
        "    x_center, y_center, box_width, box_height = path_bbox\n",
        "\n",
        "    # Convert normalized path coordinates to pixel coordinates\n",
        "    x_min = int((x_center - box_width / 2) * width)\n",
        "    x_max = int((x_center + box_width / 2) * width)\n",
        "    y_min = int((y_center - box_height / 2) * height)\n",
        "    y_max = int((y_center + box_height / 2) * height)\n",
        "\n",
        "    return x_min <= car_center_x <= x_max and y_min <= car_center_y <= y_max\n",
        "\n",
        "# List to store cars that have crossed the lower line\n",
        "crossed_lower_line = {}\n",
        "\n",
        "# List to store violation records\n",
        "violations = []\n",
        "\n",
        "def detect_and_track_violation(frame, model, path_bbox, tracker, frame_number):\n",
        "    \"\"\"Detect cars and track violations based on line crossings.\"\"\"\n",
        "    car_detections = detect_cars(frame, model, path_bbox)\n",
        "\n",
        "    if car_detections.size > 0:\n",
        "        # Track cars\n",
        "        tracked_objects = tracker.update(np.array(car_detections))\n",
        "\n",
        "        # Process each tracked object\n",
        "        for obj in tracked_objects:\n",
        "            x1, y1, x2, y2, track_id = map(int, obj)\n",
        "\n",
        "            # Get the car's center position\n",
        "            car_center_x = (x1 + x2) // 2\n",
        "            car_center_y = (y1 + y2) // 2\n",
        "\n",
        "            print(\"crossed_lower_line: \", crossed_lower_line)\n",
        "            # Check if car has crossed the lower line\n",
        "            if track_id not in crossed_lower_line:\n",
        "                if is_crossed_lower_line(car_center_y):\n",
        "                    crossed_lower_line[track_id] = {'crossed': True, 'violation': False}\n",
        "\n",
        "            # Check if car has already crossed the lower line and now crosses the upper line\n",
        "            if track_id in crossed_lower_line and crossed_lower_line[track_id]['crossed']:\n",
        "                if is_crossed_upper_line(car_center_y):\n",
        "                    crossed_lower_line[track_id]['violation'] = True\n",
        "                    violations.append({\n",
        "                        'frame_no': frame_number,\n",
        "                        'tracking_id': track_id,\n",
        "                        'bbox': (x1, y1, x2, y2)\n",
        "                    })\n",
        "\n",
        "    return violations\n",
        "\n",
        "def is_crossed_lower_line(car_center_y):\n",
        "    \"\"\"Check if car has crossed the lower line.\"\"\"\n",
        "    # Define the y-coordinate of the lower line\n",
        "    lower_line_y = (lower_line_start[1] + lower_line_end[1]) // 2\n",
        "    return car_center_y > lower_line_y\n",
        "\n",
        "def is_crossed_upper_line(car_center_y):\n",
        "    \"\"\"Check if car has crossed the upper line.\"\"\"\n",
        "    # Define the y-coordinate of the upper line\n",
        "    upper_line_y = (upper_line_start[1] + upper_line_end[1]) // 2\n",
        "    return car_center_y < upper_line_y\n",
        "\n",
        "def save_violations_to_csv(violations, csv_file_path):\n",
        "    \"\"\"Save violation records to a CSV file.\"\"\"\n",
        "    with open(csv_file_path, mode='w', newline='') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=['frame_no', 'tracking_id', 'bbox'])\n",
        "        writer.writeheader()\n",
        "        for violation in violations:\n",
        "            writer.writerow(violation)\n",
        "\n",
        "def process_and_generate_video_with_tracking(video_path, histogram_files, bbox, path_bbox, output_video_path, fps, csv_output_path):\n",
        "    # Initialize variables\n",
        "    violations = []\n",
        "    crossed_lower_line.clear()  # Reset crossed lower line state at the start\n",
        "\n",
        "    histograms = {}\n",
        "    for label, file_path in histogram_files.items():\n",
        "        histogram = load_histograms(file_path)  # Load individual histogram\n",
        "        if histogram is not None:  # Check if histogram was loaded successfully\n",
        "            histograms[label] = histogram\n",
        "\n",
        "    if not histograms:\n",
        "        logging.error(\"No histograms loaded, aborting video processing.\")\n",
        "        return\n",
        "\n",
        "    model = YOLO('yolov8n.pt')  # Use YOLOv8 pretrained model\n",
        "    if model is None:\n",
        "        return\n",
        "\n",
        "    tracker = Sort(max_age=15, min_hits=3)\n",
        "    video_capture = cv2.VideoCapture(video_path)\n",
        "    if not video_capture.isOpened():\n",
        "        logging.error(f\"Error: Unable to open video file {video_path}\")\n",
        "        return\n",
        "\n",
        "    width, height = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    frame_number = 0\n",
        "    while True:\n",
        "        ret, frame = video_capture.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Process frame and track violations\n",
        "        violations = detect_and_track_violation(frame, model, path_bbox, tracker, frame_number)\n",
        "        print(\"violation= \", violations)\n",
        "\n",
        "        # Draw lines, calculate histograms, and process detections (as per original code)\n",
        "        # Your existing drawing and bounding box logic goes here...\n",
        "\n",
        "        video_writer.write(frame)\n",
        "        frame_number += 1\n",
        "        if frame_number % 100 == 0:\n",
        "            logging.info(f\"Processed {frame_number} frames...\")\n",
        "\n",
        "    video_capture.release()\n",
        "    video_writer.release()\n",
        "\n",
        "    # Save violation records to CSV\n",
        "\n",
        "    save_violations_to_csv(violations, csv_output_path)\n",
        "    logging.info(f\"Processed video saved to {output_video_path} and violations saved to {csv_output_path}\")\n",
        "\n",
        "# Example usage\n",
        "video_path = '/content/drive/MyDrive/Input_Data/vid11_27_7_FaisalTown.mp4'\n",
        "histogram_files = {\n",
        "    \"Green\": \"/content/drive/MyDrive/Histogram/averaged_hist_Green.pkl\",\n",
        "    \"None\": \"/content/drive/MyDrive/Histogram/averaged_hist_None.pkl\",\n",
        "    \"Orange\": \"/content/drive/MyDrive/Histogram/averaged_hist_Orange.pkl\",\n",
        "    \"Red\": \"/content/drive/MyDrive/Histogram/averaged_hist_Red.pkl\"\n",
        "}\n",
        "bbox = (0.485879, 0.577487, 0.016630, 0.051067)\n",
        "path_bbox = (0.901061, 0.730515, 0.197877, 0.199434)\n",
        "output_video_path = '/content/drive/MyDrive/Resulted_violation/finalvideo.mp4'\n",
        "csv_output_path = '/content/drive/MyDrive/Resulted_violation/violations.csv'\n",
        "fps = 26\n",
        "signal_color = 'Red'\n",
        "\n",
        "process_and_generate_video_with_tracking(video_path, histogram_files, bbox, path_bbox, output_video_path, fps, csv_output_path)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PC2C7hBxs-lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title part3\n",
        "import json\n",
        "import cv2\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load tracking data\n",
        "tracking_data = pd.read_csv('/content/drive/MyDrive/Resulted_violation/violations.csv')\n",
        "\n",
        "# Function to call the license plate recognition API with retry mechanism\n",
        "def call_plate_api(image, api_key, retries=4, delay=6):\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            with open(image, 'rb') as fp:\n",
        "                response = requests.post(\n",
        "                    'https://api.platerecognizer.com/v1/plate-reader/',\n",
        "                    files={'upload': fp},\n",
        "                    headers={'Authorization': f'Token {api_key}'}\n",
        "                )\n",
        "            response.raise_for_status()  # Raise an error for a bad response (4xx, 5xx)\n",
        "            return response.json()\n",
        "        except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as e:\n",
        "            print(f\"Error: {e}. Retrying {attempt + 1}/{retries}...\")\n",
        "            time.sleep(delay)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Request failed: {e}. Skipping this object.\")\n",
        "            return None\n",
        "    print(\"Max retries reached. Skipping this object.\")\n",
        "    return None\n",
        "\n",
        "# Function to process the video\n",
        "def process_video(input_video, output_video, api_key, retry_interval=26, json_output='output.json'):\n",
        "    cap = cv2.VideoCapture(input_video)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
        "\n",
        "    # Cache for API results and retry tracking\n",
        "    plate_cache = {}\n",
        "    retry_tracker = defaultdict(lambda: -retry_interval)  # Last frame when API was called for each ID\n",
        "\n",
        "    # Data to save for JSON output\n",
        "    tracking_summary = {}\n",
        "\n",
        "    # Add progress bar\n",
        "    for frame_idx in tqdm(range(frame_count), desc=\"Processing frames\"):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Get data for the current frame from tracking data\n",
        "        frame_data = tracking_data[tracking_data['Frame'] == frame_idx]\n",
        "        for _, row in frame_data.iterrows():\n",
        "            obj_id = int(row['ID'])  # Convert to native Python int\n",
        "            x1, y1, x2, y2 = map(int, [row['x1'], row['y1'], row['x2'], row['y2']])  # Convert to Python int\n",
        "\n",
        "            # Initialize tracking summary for the object if not already present\n",
        "            if obj_id not in tracking_summary:\n",
        "                tracking_summary[obj_id] = {\"ID\": obj_id, \"start_frame\": frame_idx, \"end_frame\": frame_idx, \"plate\": \"N/A\"}\n",
        "            else:\n",
        "                tracking_summary[obj_id][\"end_frame\"] = frame_idx\n",
        "\n",
        "            # Check if plate number is already cached or if it's time to retry\n",
        "            if obj_id not in plate_cache or (plate_cache[obj_id] == 'N/A' and frame_idx - retry_tracker[obj_id] >= retry_interval):\n",
        "                # Crop the object region\n",
        "                cropped = frame[y1:y2, x1:x2]\n",
        "                cv2.imwrite('temp.jpg', cropped)\n",
        "\n",
        "                # Call the API with retries\n",
        "                api_response = call_plate_api('temp.jpg', api_key)\n",
        "                if api_response and 'results' in api_response and api_response['results']:\n",
        "                    plate_number = api_response['results'][0]['plate']\n",
        "                else:\n",
        "                    plate_number = 'N/A'\n",
        "\n",
        "                # Update cache and retry tracker\n",
        "                plate_cache[obj_id] = plate_number\n",
        "                retry_tracker[obj_id] = frame_idx\n",
        "\n",
        "                # Save plate number in tracking summary\n",
        "                tracking_summary[obj_id][\"plate\"] = plate_number\n",
        "\n",
        "            # Visualize the bounding box and plate number\n",
        "            plate_number = plate_cache[obj_id]\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "            cv2.putText(frame, plate_number, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    # Convert tracking summary values to serializable types\n",
        "    tracking_summary_serializable = {\n",
        "        k: {key: (int(value) if isinstance(value, (int, np.integer)) else value) for key, value in v.items()}\n",
        "        for k, v in tracking_summary.items()\n",
        "    }\n",
        "\n",
        "    # Save the tracking summary to a JSON file\n",
        "    with open(json_output, 'w') as json_file:\n",
        "        json.dump(list(tracking_summary_serializable.values()), json_file, indent=4)\n",
        "\n",
        "    print(f\"Video processing completed! JSON saved to {json_output}\")\n",
        "\n",
        "# Input parameters\n",
        "input_video = '/content/drive/MyDrive/Resulted_violation/finalvideo.mp4'\n",
        "output_video = '/content/drive/MyDrive/Resulted_violation/violation.mp4'\n",
        "api_key = 'df9ea40d34e80d6149f57d04d8b1328d61920916'\n",
        "json_output = '/content/drive/MyDrive/Resulted_violation/tracking_summary.json'\n",
        "\n",
        "# Process the video\n",
        "process_video(input_video, output_video, api_key, json_output=json_output)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pyQ4FRnNtSip"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}